{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "import deepl\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = deepl.Translator(input(\"Enter DeepL API key\"))\n",
    "    \n",
    "def translate_sentence(question_en):\n",
    "    return translator.translate_text(\n",
    "        question_en,\n",
    "        source_lang=\"EN\",\n",
    "        target_lang=\"PL\",\n",
    "        formality='prefer_less',\n",
    "        preserve_formatting=True,\n",
    "    ).text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple names translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../spider-en/tables.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = []\n",
    "columns = []\n",
    "\n",
    "for entry in data:\n",
    "    tables_names = entry['table_names']\n",
    "    tables_names_original = entry['table_names_original']\n",
    "    column_names = entry['column_names']\n",
    "    column_names_original = entry['column_names_original']\n",
    "    db_id = entry['db_id']\n",
    "    foreign_keys = entry['foreign_keys']\n",
    "    primary_keys = entry['primary_keys']\n",
    "    \n",
    "    foreign_keys = {a: tables_names[column_names[b][0]] for (a, b) in foreign_keys}\n",
    "    \n",
    "    for name, name_original in zip(tables_names, tables_names_original):\n",
    "        entry = {\n",
    "            'db_id': db_id,\n",
    "            'name': name,\n",
    "            'name_original': name_original\n",
    "        }\n",
    "        tables.append(entry)\n",
    "        \n",
    "    for column_idx, ((table_idx, name), (_, column_name_original)) in enumerate(zip(column_names, column_names_original)):\n",
    "        if name == '*':\n",
    "            continue\n",
    "        \n",
    "        entry = {\n",
    "            'db_id': db_id,\n",
    "            'table_name': tables_names[table_idx],\n",
    "            'column_name': name,\n",
    "            'column_name_original': column_name_original,\n",
    "            'primary_key': column_idx in primary_keys,\n",
    "            'foreign_key': foreign_keys.get(column_idx, '')\n",
    "        }\n",
    "        columns.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_name(name, container_name, other_container_name=None):\n",
    "    container_name = re.sub(r'[^a-zA-Z ]', ' ', container_name)\n",
    "    if not other_container_name:\n",
    "        text = f\"{name} (from {container_name})\"\n",
    "    else:\n",
    "        other_container_name = re.sub(r'[^a-zA-Z ]', ' ', other_container_name)\n",
    "        text = f\"{name} (from {container_name} and {other_container_name})\"\n",
    "    text_pl = translate_sentence(text)\n",
    "    paren_idx = text_pl.index('(')\n",
    "    return text_pl[:paren_idx].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4503it [09:07,  8.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# translate columns\n",
    "path = '../auxiliary/translated_schema/columns_names.json'\n",
    "\n",
    "for i, table in tqdm(enumerate(columns), total=len(columns)):\n",
    "    name_pl = translate_name(table['column_name'], table['table_name'], table['db_id'])\n",
    "    table['column_name_pl'] = name_pl\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(columns, f, indent=4, ensure_ascii=False)\n",
    "            \n",
    "with open(path, 'w') as f:\n",
    "    json.dump(columns, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 876/876 [01:44<00:00,  8.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# translate tables\n",
    "path = '../auxiliary/translated_schema/tables_names.json'\n",
    "\n",
    "for i, table in tqdm(enumerate(tables), total=len(tables)):\n",
    "    name_pl = translate_name(table['name'], table['db_id'])\n",
    "    table['name_pl'] = name_pl\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(tables, f, indent=4, ensure_ascii=False)\n",
    "            \n",
    "with open(path, 'w') as f:\n",
    "    json.dump(tables, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking suspicious translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of columns names which translated name is the same as oryginal - to check them manually\n",
    "with open('../auxiliary/translated_schema/columns_names.json', 'r') as f:\n",
    "    columns = json.load(f)\n",
    "\n",
    "suspicious_columns = [column['column_name_pl'] for column in columns if column['column_name'].lower() == column['column_name_pl'].lower()]\n",
    "suspicious_columns = list(set(suspicious_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of tables names which translated name is the same as oryginal - to check them manually\n",
    "with open('../auxiliary/translated_schema/tables_names.json', 'r') as f:\n",
    "    tables = json.load(f)\n",
    "\n",
    "for table in tables:\n",
    "    if table['name'].lower() == table['name_pl'].lower():\n",
    "        print(table['name'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking names conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../auxiliary/translated_schema/columns_names.json', 'r') as f:\n",
    "    columns = json.load(f)\n",
    "    \n",
    "db_ids = set(column['db_id'] for column in columns)\n",
    "for db_id in db_ids:\n",
    "    tables_names = set(column['table_name'] for column in columns if column['db_id'] == db_id)\n",
    "    for table_name in tables_names:\n",
    "        columns_names = [column['column_name_pl'] for column in columns if column['db_id'] == db_id and column['table_name'] == table_name]\n",
    "        duplicates = set([name for name in columns_names if len([x for x in columns_names if x == name]) > 1])\n",
    "        if duplicates:\n",
    "            print(f'Conflicting columns {duplicates} in table {table_name} in database {db_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../auxiliary/translated_schema/tables_names.json', 'r') as f:\n",
    "    tables = json.load(f)\n",
    "    \n",
    "db_ids = set(column['db_id'] for column in columns)\n",
    "for db_id in db_ids:\n",
    "    tables_names = list(table['name_pl'] for table in tables if table['db_id'] == db_id)\n",
    "    duplicates = set([name for name in tables_names if len([x for x in tables_names if x == name]) > 1])\n",
    "    if duplicates:\n",
    "        print(f'Conflicting columns {duplicates} in table {table_name} in database {db_id}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oryginal names translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice, choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../auxiliary/translated_schema/columns_names.json', 'r') as f:\n",
    "    columns = json.load(f)\n",
    "    \n",
    "with open('../auxiliary/translated_schema/tables_names.json', 'r') as f:\n",
    "    tables = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3847 / 656\n"
     ]
    }
   ],
   "source": [
    "difficult_columns = []\n",
    "simple_columns = []\n",
    "for column in columns:\n",
    "    name = column['column_name_original']\n",
    "    simple = all([part == part.upper() or part == part.lower() or part == part.capitalize() for part in name.split('_')])\n",
    "    \n",
    "    if (name == name.lower() or name == name.upper() or simple) and len(name) > 3:\n",
    "        simple_columns.append(column)\n",
    "    else:\n",
    "        difficult_columns.append(column)\n",
    "        \n",
    "print(len(simple_columns), '/', len(difficult_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Start_Date', 'msid', 'catalog_entry_id', 'Claim_Status_Code', 'candidate_id', 'Major', 'amenity_name', 'next_entry_id', 'Date_Payment_Made', 'Competition_ID']\n"
     ]
    }
   ],
   "source": [
    "print([column['column_name_original'] for column in choices(simple_columns, k=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aug', 'CheckIn', 'Age', 'ID', 'CheckIn', 'id', 'lat', 'cs', 'eid', 'g_c']\n"
     ]
    }
   ],
   "source": [
    "print([column['column_name_original'] for column in choices(difficult_columns, k=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'db_id': 'perpetrator',\n",
       " 'table_name': 'perpetrator',\n",
       " 'column_name': 'perpetrator id',\n",
       " 'column_name_original': 'Perpetrator_ID',\n",
       " 'primary_key': True,\n",
       " 'foreign_key': '',\n",
       " 'column_name_pl': 'identyfikator sprawcy'}"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names_translations = {table['name']: table['name_pl'] for table in tables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "batch = choices(difficult_columns, k=100)\n",
    "for column in batch:\n",
    "    table_name_pl = table_names_translations[column['table_name']]\n",
    "    text = f\"{column['column_name_original']} ({column['column_name']} - {column['column_name_pl']}) from {column['table_name']} ({table_name_pl})\"\n",
    "    print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_from_table(db_id, table_name):\n",
    "    with open('../../spider-en/tables.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "    db = [db for db in data if db['db_id'] == db_id][0]\n",
    "    table_idx = db['table_names'].index(table_name)\n",
    "    columns = [column[1] for column in db['column_names'] if column[0] == table_idx]\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_columns_from_table('cre_Drama_Workshop_Groups', 'clients')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polish-spider",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
