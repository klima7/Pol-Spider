{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pprint import pprint\n",
    "from random import choice, choices\n",
    "\n",
    "import deepl\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = deepl.Translator(input(\"Enter DeepL API key\"))\n",
    "    \n",
    "def translate_sentence(question_en):\n",
    "    return translator.translate_text(\n",
    "        question_en,\n",
    "        source_lang=\"EN\",\n",
    "        target_lang=\"PL\",\n",
    "        formality='prefer_less',\n",
    "        preserve_formatting=True,\n",
    "    ).text\n",
    "    \n",
    "def translate_phrase(value_en):\n",
    "    return translator.translate_text(\n",
    "        value_en,\n",
    "        source_lang=\"EN\",\n",
    "        target_lang=\"PL\",\n",
    "        preserve_formatting=True,\n",
    "        split_sentences='off',\n",
    "        formality='prefer_less'\n",
    "    ).text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple names translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../spider-en/tables.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = []\n",
    "columns = []\n",
    "\n",
    "for entry in data:\n",
    "    tables_names = entry['table_names']\n",
    "    tables_names_original = entry['table_names_original']\n",
    "    column_names = entry['column_names']\n",
    "    column_names_original = entry['column_names_original']\n",
    "    db_id = entry['db_id']\n",
    "    foreign_keys = entry['foreign_keys']\n",
    "    primary_keys = entry['primary_keys']\n",
    "    \n",
    "    foreign_keys = {a: tables_names[column_names[b][0]] for (a, b) in foreign_keys}\n",
    "    \n",
    "    for name, name_original in zip(tables_names, tables_names_original):\n",
    "        entry = {\n",
    "            'db_id': db_id,\n",
    "            'name': name,\n",
    "            'name_original': name_original\n",
    "        }\n",
    "        tables.append(entry)\n",
    "        \n",
    "    for column_idx, ((table_idx, name), (_, column_name_original)) in enumerate(zip(column_names, column_names_original)):\n",
    "        if name == '*':\n",
    "            continue\n",
    "        \n",
    "        entry = {\n",
    "            'db_id': db_id,\n",
    "            'table_name_original': tables_names_original[table_idx],\n",
    "            'column_name': name,\n",
    "            'column_name_original': column_name_original,\n",
    "            'primary_key': column_idx in primary_keys,\n",
    "            'foreign_key': foreign_keys.get(column_idx, '')\n",
    "        }\n",
    "        columns.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_name(name, container_name, other_container_name=None):\n",
    "    container_name = re.sub(r'[^a-zA-Z ]', ' ', container_name)\n",
    "    if not other_container_name:\n",
    "        text = f\"{name} (from {container_name})\"\n",
    "    else:\n",
    "        other_container_name = re.sub(r'[^a-zA-Z ]', ' ', other_container_name)\n",
    "        text = f\"{name} (from {container_name} and {other_container_name})\"\n",
    "    text_pl = translate_sentence(text)\n",
    "    paren_idx = text_pl.index('(')\n",
    "    return text_pl[:paren_idx].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4503it [09:07,  8.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# translate columns\n",
    "path = '../auxiliary/translated_schema/columns_names.json'\n",
    "\n",
    "for i, table in tqdm(enumerate(columns), total=len(columns)):\n",
    "    name_pl = translate_name(table['column_name'], table['table_name'], table['db_id'])\n",
    "    table['column_name_pl'] = name_pl\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(columns, f, indent=4, ensure_ascii=False)\n",
    "            \n",
    "with open(path, 'w') as f:\n",
    "    json.dump(columns, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 876/876 [01:44<00:00,  8.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# translate tables\n",
    "path = '../auxiliary/translated_schema/tables_names.json'\n",
    "\n",
    "for i, table in tqdm(enumerate(tables), total=len(tables)):\n",
    "    name_pl = translate_name(table['name'], table['db_id'])\n",
    "    table['name_pl'] = name_pl\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(tables, f, indent=4, ensure_ascii=False)\n",
    "            \n",
    "with open(path, 'w') as f:\n",
    "    json.dump(tables, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking suspicious translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of columns names which translated name is the same as oryginal - to check them manually\n",
    "with open('../auxiliary/translated_schema/columns_names.json', 'r') as f:\n",
    "    columns = json.load(f)\n",
    "\n",
    "suspicious_columns = [column['column_name_original_pl'] for column in columns if column['column_name_original'].lower() == column['column_name_original_pl'].lower()]\n",
    "suspicious_columns = list(set(suspicious_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of tables names which translated name is the same as oryginal - to check them manually\n",
    "with open('../auxiliary/translated_schema/tables_names.json', 'r') as f:\n",
    "    tables = json.load(f)\n",
    "\n",
    "for table in tables:\n",
    "    if table['name'].lower() == table['name_pl'].lower():\n",
    "        print(table['name'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking names conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../auxiliary/translated_schema/columns_names.json', 'r') as f:\n",
    "    columns = json.load(f)\n",
    "    \n",
    "db_ids = set(column['db_id'] for column in columns)\n",
    "for db_id in db_ids:\n",
    "    tables_names = set(column['table_name'] for column in columns if column['db_id'] == db_id)\n",
    "    for table_name in tables_names:\n",
    "        columns_names = [column['column_name_pl'] for column in columns if column['db_id'] == db_id and column['table_name'] == table_name]\n",
    "        duplicates = set([name for name in columns_names if len([x for x in columns_names if x == name]) > 1])\n",
    "        if duplicates:\n",
    "            print(f'Conflicting columns {duplicates} in table {table_name} in database {db_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../auxiliary/translated_schema/tables_names.json', 'r') as f:\n",
    "    tables = json.load(f)\n",
    "    \n",
    "db_ids = set(column['db_id'] for column in columns)\n",
    "for db_id in db_ids:\n",
    "    tables_names = list(table['name_pl'] for table in tables if table['db_id'] == db_id)\n",
    "    duplicates = set([name for name in tables_names if len([x for x in tables_names if x == name]) > 1])\n",
    "    if duplicates:\n",
    "        print(f'Conflicting columns {duplicates} in table {table_name} in database {db_id}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oryginal names translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3847 / 656\n"
     ]
    }
   ],
   "source": [
    "# find diffucult columns names\n",
    "with open('../auxiliary/translated_schema/columns_names.json', 'r') as f:\n",
    "    columns = json.load(f)\n",
    "\n",
    "difficult_columns = []\n",
    "simple_columns = []\n",
    "for column in columns:\n",
    "    name = column['column_name_original']\n",
    "    simple = all([part == part.upper() or part == part.lower() or part == part.capitalize() for part in name.split('_')])\n",
    "    \n",
    "    if (name == name.lower() or name == name.upper() or simple) and len(name) > 3:\n",
    "        simple_columns.append(column)\n",
    "    else:\n",
    "        difficult_columns.append(column)\n",
    "        \n",
    "print(len(simple_columns), '/', len(difficult_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862 / 14\n"
     ]
    }
   ],
   "source": [
    "# find difficult tables names\n",
    "with open('../auxiliary/translated_schema/tables_names.json', 'r') as f:\n",
    "    tables = json.load(f)\n",
    "\n",
    "difficult_tables = []\n",
    "simple_tables = []\n",
    "for table in tables:\n",
    "    name = table['name_original']\n",
    "    simple = all([part == part.upper() or part == part.lower() or part == part.capitalize() for part in name.split('_')])\n",
    "    \n",
    "    if (name == name.lower() or name == name.upper() or simple) and len(name) > 3:\n",
    "        simple_tables.append(column)\n",
    "    else:\n",
    "        difficult_tables.append(column)\n",
    "        \n",
    "print(len(simple_tables), '/', len(difficult_tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate name\n",
    "def translate_original_name(name, container, other_container=None):\n",
    "    natural_text_en = name.replace('_', ' ')\n",
    "    was_titled = all(word[0]==word[0].upper() and word[1:]==word[1:].lower() for word in natural_text_en.split(' '))\n",
    "    natural_text_pl = translate_name(natural_text_en, container, other_container)\n",
    "    if was_titled:\n",
    "        natural_text_pl = natural_text_pl.title()\n",
    "    return natural_text_pl.replace(' ', \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 876/876 [01:36<00:00,  9.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# translate tables\n",
    "path = '../auxiliary/translated_schema/tables_names.json'\n",
    "\n",
    "for i, table in tqdm(enumerate(tables), total=len(tables)):\n",
    "    name_pl = translate_original_name(table['name_original'], table['db_id'])\n",
    "    table['name_original_pl'] = name_pl\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(tables, f, indent=4, ensure_ascii=False)\n",
    "            \n",
    "with open(path, 'w') as f:\n",
    "    json.dump(tables, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4503 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4503/4503 [01:43<00:00, 43.43it/s]   \n"
     ]
    }
   ],
   "source": [
    "# translate columns\n",
    "path = '../auxiliary/translated_schema/columns_names.json'\n",
    "\n",
    "with open(path, 'r') as f:\n",
    "    columns = json.load(f)\n",
    "\n",
    "for i, column in tqdm(enumerate(columns), total=len(columns)):\n",
    "    if 'column_name_original_pl' in column:\n",
    "        continue\n",
    "    name_pl = translate_original_name(column['column_name_original'], column['table_name'], column['db_id'])\n",
    "    column['column_name_original_pl'] = name_pl\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(columns, f, indent=4, ensure_ascii=False)\n",
    "            \n",
    "with open(path, 'w') as f:\n",
    "    json.dump(columns, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find suspicious columns\n",
    "with open('../auxiliary/translated_schema/columns_names.json', 'r') as f:\n",
    "    columns = json.load(f)\n",
    "\n",
    "suspicious_columns = [column['column_name_original_pl'] for column in columns if column['column_name_original'] == column['column_name_original_pl']]\n",
    "suspicious_columns = list(set(suspicious_columns))\n",
    "len(suspicious_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bfp', 'buildUpPlayDribblingClass', 'gid', 'eid', 'chanceCreationPassing', 'sec_id', 'defenceTeamWidthClass', 'status', 'InvoiceId', 'AId']\n"
     ]
    }
   ],
   "source": [
    "print(choices(suspicious_columns, k=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns:\n",
    "    if column['column_name_original'] == column['column_name_original_pl']:\n",
    "        column['column_name_original_pl'] += '?'\n",
    "        \n",
    "with open(path, 'w') as f:\n",
    "    json.dump(columns, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make columns names similar to original\n",
    "with open('../auxiliary/translated_schema/columns_names.json', 'r') as f:\n",
    "    columns = json.load(f)\n",
    "    \n",
    "for column in columns:\n",
    "    if column['column_name'].lower() == column['column_name_original'].lower().replace('_', ' '):\n",
    "        column['column_name_pl'] = column['column_name_original_pl'].lower().replace('_', ' ')\n",
    "        \n",
    "with open('../auxiliary/translated_schema/columns_names.json', 'w') as f:\n",
    "    json.dump(columns, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_original_name(name):\n",
    "    natural_text_en = name.replace('_', ' ')\n",
    "    was_titled = all(word[0]==word[0].upper() and word[1:]==word[1:].lower() for word in natural_text_en.split(' '))\n",
    "    natural_text_pl = translate_phrase(natural_text_en)\n",
    "    if was_titled:\n",
    "        natural_text_pl = natural_text_pl.title()\n",
    "    return natural_text_pl.replace(' ', \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................"
     ]
    }
   ],
   "source": [
    "# fix _ID issue\n",
    "with open('../auxiliary/translated_schema/columns_names.json', 'r') as f:\n",
    "    columns = json.load(f)\n",
    "    \n",
    "for column in columns:\n",
    "    if column['column_name_original'].lower().endswith('_id') and column['column_name_original_pl'].lower().startswith('id'):\n",
    "        column['column_name_original_pl'] = translate_original_name(column['column_name_original'][:-3]) + column['column_name_original'][-3:]\n",
    "        print('.', end='')\n",
    "        \n",
    "with open('../auxiliary/translated_schema/columns_names.json', 'w') as f:\n",
    "    json.dump(columns, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tables names conflicts\n",
    "with open('../auxiliary/translated_schema/tables_names.json', 'r') as f:\n",
    "    tables = json.load(f)\n",
    "    \n",
    "db_ids = set(column['db_id'] for column in columns)\n",
    "for db_id in db_ids:\n",
    "    tables_names = list(table['name_original_pl'] for table in tables if table['db_id'] == db_id)\n",
    "    duplicates = set([name for name in tables_names if len([x for x in tables_names if x == name]) > 1])\n",
    "    if duplicates:\n",
    "        print(f'Conflicting columns {duplicates} in table {table_name} in database {db_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['line_2', 'Gold', 'resident_id', 'asessment_outcome_code', 'Mountain_ID', 'g_2b', 'player_id', 'All_Games_Percent', 'Profits_in_Billion', 'customer_id']\n"
     ]
    }
   ],
   "source": [
    "print([column['column_name_original'] for column in choices(simple_columns, k=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sh', 'Id', 'id', 'seq', 'buildUpPlaySpeed', 'g', 'h', 'w', 'bpf', 'PetType']\n"
     ]
    }
   ],
   "source": [
    "print([column['column_name_original'] for column in choices(difficult_columns, k=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for GPT\n",
    "table_names_translations = {table['name']: table['name_pl'] for table in tables}\n",
    "batch = choices(simple_columns, k=100)\n",
    "for column in batch:\n",
    "    table_name_pl = table_names_translations[column['table_name']]\n",
    "    text = f\"{column['column_name_original']} ({column['column_name']} - {column['column_name_pl']}) from \\\"{column['table_name']}\\\" ({table_name_pl})\"\n",
    "    if column['foreign_key']:\n",
    "        foreign_key_pl = table_names_translations[column['foreign_key']]\n",
    "        text += f\" in relation with \\\"{column['foreign_key']}\\\" ({foreign_key_pl})\"\n",
    "    text += ' -> '\n",
    "    print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_from_table(db_id, table_name):\n",
    "    with open('../../spider-en/tables.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "    db = [db for db in data if db['db_id'] == db_id][0]\n",
    "    table_idx = db['table_names'].index(table_name)\n",
    "    columns = [column[1] for column in db['column_names'] if column[0] == table_idx]\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'name',\n",
       " 'album id',\n",
       " 'media type id',\n",
       " 'genre id',\n",
       " 'composer',\n",
       " 'milliseconds',\n",
       " 'bytes',\n",
       " 'unit price']"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_columns_from_table('store_1', 'tracks')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polish-spider",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
