{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import deepl\n",
    "import gdown\n",
    "import sqlparse\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download oryginal spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_spider(directory_name):\n",
    "    id = \"1TqleXec_OykOYFREKKtschzY29dUcVAQ\"\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        zip_path = str(Path(tmp_dir) / \"spider.zip\")\n",
    "        gdown.download(id=id, output=zip_path, quiet=False)\n",
    "        shutil.unpack_archive(zip_path, None)\n",
    "        shutil.move('spider', directory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1TqleXec_OykOYFREKKtschzY29dUcVAQ\n",
      "From (redirected): https://drive.google.com/uc?id=1TqleXec_OykOYFREKKtschzY29dUcVAQ&confirm=t&uuid=e5443417-8c83-44d6-a146-deece5a3310c\n",
      "To: /tmp/tmp1r6xhh2f/spider.zip\n",
      "100%|██████████| 99.7M/99.7M [00:01<00:00, 68.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "download_spider('../../spider-en')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepL Translation toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = deepl.Translator(input(\"Enter DeepL API key\"))\n",
    "\n",
    "def translate_sentence(question_en):\n",
    "    return translator.translate_text(\n",
    "        question_en,\n",
    "        source_lang=\"EN\",\n",
    "        target_lang=\"PL\",\n",
    "        formality='prefer_less'\n",
    "    ).text\n",
    "    \n",
    "    \n",
    "def translate_phrase(value_en):\n",
    "    if value_en.strip() == '':\n",
    "        return ''\n",
    "    \n",
    "    return translator.translate_text(\n",
    "        value_en,\n",
    "        source_lang=\"EN\",\n",
    "        target_lang=\"PL\",\n",
    "        preserve_formatting=True,\n",
    "        split_sentences='off',\n",
    "        formality='prefer_less'\n",
    "    ).text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tokens_to_translate(statement):\n",
    "    tokens = [token for token in statement.flatten() if str(token).strip() != '']\n",
    "    \n",
    "    tokens_to_translate = []\n",
    "    for i in range(len(tokens)):\n",
    "        if str(tokens[i].ttype).startswith('Token.Literal.String'):\n",
    "            # do not translate \n",
    "            if i > 0 and str(tokens[i-1]).lower() == 'like':\n",
    "                continue\n",
    "            tokens_to_translate.append(tokens[i])\n",
    "        \n",
    "    return tokens_to_translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_token(token):\n",
    "    assert \"'\" in token.value or '\"' in token.value\n",
    "    value_en = token.value.strip(\"'\\\" \")\n",
    "    value_pl = translate_phrase(value_en)\n",
    "    token.value = f'\"{value_pl}\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_query(query):\n",
    "    statement = sqlparse.parse(query)[0]\n",
    "    tokens = find_tokens_to_translate(statement)\n",
    "\n",
    "    for token in tokens:\n",
    "        translate_token(token)\n",
    "        \n",
    "    return str(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_quotes(sentence):\n",
    "    matches = re.finditer(r\"['\\\"](.*?)['\\\"]\", sentence)\n",
    "    sentence = list(sentence)\n",
    "    for match in reversed(list(matches)):\n",
    "        start, end = match.start(), match.end()\n",
    "        text = ''.join(sentence[start:end])\n",
    "        text_pl = translate_phrase(text)\n",
    "        sentence[start:end] = text_pl\n",
    "    return ''.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_question(question):\n",
    "    stage1 = translate_phrase(question)\n",
    "    stage2 = translate_quotes(stage1)\n",
    "    return stage2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_file(src_path, dst_path):\n",
    "    with open(src_path) as json_data:\n",
    "        samples_en = json.load(json_data)\n",
    "        \n",
    "    samples_pl = []\n",
    "        \n",
    "    for i, sample in tqdm(enumerate(samples_en), total=len(samples_en)):\n",
    "        db_id = sample['db_id']\n",
    "        question_en = sample['question']\n",
    "        query_en = sample['query']\n",
    "        \n",
    "        question_pl = translate_question(question_en)\n",
    "        query_pl = translate_query(query_en)\n",
    "        \n",
    "        sample_pl = {\n",
    "            'db_id': db_id,\n",
    "            'question': question_en,\n",
    "            'question_pl': question_pl,\n",
    "            'query': query_en,\n",
    "            'query_pl': query_pl\n",
    "        }\n",
    "        \n",
    "        samples_pl.append(sample_pl)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            with open(dst_path, 'w') as f:\n",
    "                json.dump(samples_pl, f, indent=4, ensure_ascii=False)\n",
    "                \n",
    "        with open(dst_path, 'w') as f:\n",
    "            json.dump(samples_pl, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'train_spider.json'    # one of dev, train_others, train_spider\n",
    "\n",
    "spider_path = Path('../auxiliary/machine_translated')\n",
    "target_path = Path('../auxiliary/machine_translated2')\n",
    "\n",
    "translate_file(\n",
    "    spider_path / file,\n",
    "    target_path / file\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polish-spider",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
